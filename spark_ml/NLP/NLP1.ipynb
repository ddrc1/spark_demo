{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "460764df-06a8-4f19-89bf-47b5efd9b19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import findspark\n",
    "findspark.init(os.getenv('SPARK_HOME'))\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.ml.feature import StopWordsRemover, NGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9802680-66a0-40c8-b227-1f8c4048d261",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/28 12:59:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('nlp').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f0c3c1f-7b22-4607-aff0-d0986781f3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| id|            sentence|\n",
      "+---+--------------------+\n",
      "|  0|Hi I heard about ...|\n",
      "|  1|I wish java could...|\n",
      "|  2|Logistic,Regressi...|\n",
      "+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([\n",
    "                            (0, 'Hi I heard about Spark'),\n",
    "                            (1, 'I wish java could use case classes'), \n",
    "                            (2, 'Logistic,Regression,models,are,neat')\n",
    "                            ], ['id', 'sentence'])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22ee8018-6d77-498e-8e26-fc020545e272",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol='sentence', outputCol='words')\n",
    "regex_tokenizer = RegexTokenizer(inputCol='sentence', outputCol='words', pattern='\\\\W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e03a97d2-d4c9-4fe6-af96-5bf8352581df",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tokens = udf(lambda words: len(words), IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f3edf99-ea5d-45d9-8ae8-99a10e64de6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = tokenizer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d4ee120-5aea-4768-8ef6-7a820390e48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+------+\n",
      "| id|            sentence|               words|tokens|\n",
      "+---+--------------------+--------------------+------+\n",
      "|  0|Hi I heard about ...|[hi, i, heard, ab...|     5|\n",
      "|  1|I wish java could...|[i, wish, java, c...|     7|\n",
      "|  2|Logistic,Regressi...|[logistic,regress...|     1|\n",
      "+---+--------------------+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized.withColumn('tokens', count_tokens(col('words'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd6ed768-ae44-47a2-b4f1-981255b4c7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+\n",
      "| id|            sentence|               words|\n",
      "+---+--------------------+--------------------+\n",
      "|  0|Hi I heard about ...|[hi, i, heard, ab...|\n",
      "|  1|I wish java could...|[i, wish, java, c...|\n",
      "|  2|Logistic,Regressi...|[logistic, regres...|\n",
      "+---+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rg_tokenized = regex_tokenizer.transform(df)\n",
    "rg_tokenized.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9748116-8d7e-4c35-8b21-9c78360da5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+------+\n",
      "| id|            sentence|               words|tokens|\n",
      "+---+--------------------+--------------------+------+\n",
      "|  0|Hi I heard about ...|[hi, i, heard, ab...|     5|\n",
      "|  1|I wish java could...|[i, wish, java, c...|     7|\n",
      "|  2|Logistic,Regressi...|[logistic, regres...|     5|\n",
      "+---+--------------------+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rg_tokenized.withColumn('tokens', count_tokens(col('words'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "858733b4-faca-4c0d-86bd-9c2a49133f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| id|              tokens|\n",
      "+---+--------------------+\n",
      "|  0|[I, saw, the, gre...|\n",
      "|  1|[Mary, had, a, li...|\n",
      "+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = spark.createDataFrame([\n",
    "                            (0, ['I', 'saw', 'the', 'green', 'horse']),\n",
    "                            (1, ['Mary', 'had', 'a', 'little', 'lamb']), \n",
    "                            ], ['id', 'tokens'])\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9382dbb7-f929-4e49-9c3d-14a17f7a83b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+\n",
      "| id|              tokens|            filtered|\n",
      "+---+--------------------+--------------------+\n",
      "|  0|[I, saw, the, gre...| [saw, green, horse]|\n",
      "|  1|[Mary, had, a, li...|[Mary, little, lamb]|\n",
      "+---+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "remover = StopWordsRemover(inputCol='tokens', outputCol='filtered')\n",
    "remover.transform(df2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c2e74d5-62b8-4bab-9264-c9ecdd52ba79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| id|               words|\n",
      "+---+--------------------+\n",
      "|  0|[Hi, I, heard, ab...|\n",
      "|  1|[I, wish, java, c...|\n",
      "|  2|[Logistic, Regres...|\n",
      "+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = spark.createDataFrame([\n",
    "                            (0, ['Hi', 'I', 'heard', 'about', 'Spark']),\n",
    "                            (1, ['I', 'wish', 'java', 'could', 'use', 'case', 'classes']),\n",
    "                            (2, ['Logistic', 'Regression', 'models', 'are', 'neat'])\n",
    "                            ], ['id', 'words'])\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dcd41271-40fd-482e-9929-6bae6470a448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------------------------------+------------------------------------------------------------------+\n",
      "|id |words                                     |grams                                                             |\n",
      "+---+------------------------------------------+------------------------------------------------------------------+\n",
      "|0  |[Hi, I, heard, about, Spark]              |[Hi I, I heard, heard about, about Spark]                         |\n",
      "|1  |[I, wish, java, could, use, case, classes]|[I wish, wish java, java could, could use, use case, case classes]|\n",
      "|2  |[Logistic, Regression, models, are, neat] |[Logistic Regression, Regression models, models are, are neat]    |\n",
      "+---+------------------------------------------+------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ngram = NGram(n=2, inputCol='words', outputCol='grams')\n",
    "ngram.transform(df3).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eff51c-5347-4638-8ed2-5915052c6e47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
